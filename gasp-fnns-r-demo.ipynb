{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# packages for gasp\n",
    "import imageio\n",
    "import json\n",
    "import torch\n",
    "from viz.plots import plot_point_cloud_batch, plot_voxels_batch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.conversion import GridDataConverter, PointCloudDataConverter\n",
    "# Note that this import is necessary for load_function_distribution\n",
    "# properly instantiate the FourierFeatures\n",
    "from models.function_representation import FourierFeatures\n",
    "from models.function_distribution import load_function_distribution\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# GASP Generater ########################################################\n",
    "gasp_device = torch.device('cuda')\n",
    "\n",
    "exp_dir = 'trained-models/celebahq64'  # 修改此处\n",
    "\n",
    "with open(exp_dir + '/config.json') as f:  # 修改此处\n",
    "    config = json.load(f)\n",
    "\n",
    "# Create appropriate data converter based on config\n",
    "if config[\"dataset\"] == 'mnist':\n",
    "    data_shape = (1, config[\"resolution\"], config[\"resolution\"])\n",
    "    data_converter = GridDataConverter(gasp_device, data_shape,\n",
    "                                       normalize_features=True)\n",
    "elif config[\"dataset\"] == 'celebahq':\n",
    "    data_shape = (3, config[\"resolution\"], config[\"resolution\"])\n",
    "    data_converter = GridDataConverter(gasp_device, data_shape,\n",
    "                                       normalize_features=True)\n",
    "elif config[\"dataset\"] == 'shapenet_voxels':\n",
    "    data_shape = (1, config[\"resolution\"], config[\"resolution\"], config[\"resolution\"])\n",
    "    data_converter = GridDataConverter(gasp_device, data_shape,\n",
    "                                       normalize_features=True)\n",
    "elif config[\"dataset\"] == 'shapenet_point_clouds':\n",
    "    data_shape = (1, config[\"resolution\"], config[\"resolution\"], config[\"resolution\"])\n",
    "    data_converter = PointCloudDataConverter(gasp_device, data_shape,\n",
    "                                             normalize_features=True)\n",
    "\n",
    "# Load function distribution weights\n",
    "func_dist = load_function_distribution(gasp_device, exp_dir + '/model_100.pt')  # 修改此处\n",
    "func_dist.to('cuda')\n",
    "\n",
    "# Sample one image from model\n",
    "num_samples = [1]\n",
    "latent_z = func_dist.latent_distribution.sample((num_samples))\n",
    "\n",
    "samples = func_dist.sample_data_by_latent(data_converter, latent_z, num_samples=1)\n",
    "\n",
    "# Convert list of samples to batch of samples\n",
    "samples = torch.cat([sample.unsqueeze(0) for sample in samples], dim=0).detach()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64])\n",
      "eps: 0.3\n",
      "adv latent grad\n",
      "0 0.249267578125\n",
      "adv latent grad\n",
      "1 0.149658203125\n",
      "adv latent grad\n",
      "2 0.09228515625\n",
      "adv latent grad\n",
      "3 0.04638671875\n",
      "adv latent grad\n",
      "4 0.02099609375\n",
      "adv latent grad\n",
      "5 0.009033203125\n",
      "adv latent grad\n",
      "6 0.00390625\n",
      "adv latent grad\n",
      "7 0.001220703125\n",
      "adv latent grad\n",
      "8 0.0\n",
      "11111\n",
      "psnr: 39.07732301630668\n",
      "ssim: 0.9732644093993917\n",
      "error: 0.0\n"
     ]
    }
   ],
   "source": [
    "# fixed neural network #########################################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread, imwrite\n",
    "from torch import nn\n",
    "import random\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity\n",
    "from steganogan import SteganoGAN\n",
    "from steganogan.encoders import BasicEncoder\n",
    "from steganogan.decoders import BasicDecoder\n",
    "from steganogan.critics import BasicCritic\n",
    "\n",
    "import torch\n",
    "from torch.optim import LBFGS\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# set seed\n",
    "seed = 11111\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# L1 = np.random.randn(3, 3)\n",
    "# print(L1)\n",
    "#\n",
    "# np.random.seed(seed)\n",
    "# L2 = np.random.randn(3, 3)\n",
    "# print(L2)\n",
    "\n",
    "from math import log10\n",
    "import cv2\n",
    "\n",
    "def calc_psnr(img1, img2):\n",
    "    ### args:\n",
    "        # img1: [h, w, c], range [0, 255]\n",
    "        # img2: [h, w, c], range [0, 255]\n",
    "    diff = (img1 - img2) / 255.0\n",
    "    diff[:,:,0] = diff[:,:,0] * 65.738 / 256.0\n",
    "    diff[:,:,1] = diff[:,:,1] * 129.057 / 256.0\n",
    "    diff[:,:,2] = diff[:,:,2] * 25.064 / 256.0\n",
    "\n",
    "    diff = np.sum(diff, axis=2)\n",
    "    mse = np.mean(np.power(diff, 2))\n",
    "    return -10 * log10(mse)\n",
    "\n",
    "def calc_ssim(img1, img2):\n",
    "    def ssim(img1, img2):\n",
    "        C1 = (0.01 * 255)**2\n",
    "        C2 = (0.03 * 255)**2\n",
    "\n",
    "        img1 = img1.astype(np.float64)\n",
    "        img2 = img2.astype(np.float64)\n",
    "        kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "        window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "        mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "        mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "        mu1_sq = mu1**2\n",
    "        mu2_sq = mu2**2\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "        sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "        sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "        sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
    "                                                                (sigma1_sq + sigma2_sq + C2))\n",
    "        return ssim_map.mean()\n",
    "\n",
    "    ### args:\n",
    "        # img1: [h, w, c], range [0, 255]\n",
    "        # img2: [h, w, c], range [0, 255]\n",
    "        # the same outputs as MATLAB's\n",
    "    border = 0\n",
    "    img1_y = np.dot(img1, [65.738,129.057,25.064])/256.0+16.0\n",
    "    img2_y = np.dot(img2, [65.738,129.057,25.064])/256.0+16.0\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    h, w = img1.shape[:2]\n",
    "    img1_y = img1_y[border:h-border, border:w-border]\n",
    "    img2_y = img2_y[border:h-border, border:w-border]\n",
    "    img2_y = img2_y[border:h-border, border:w-border]\n",
    "\n",
    "    if img1_y.ndim == 2:\n",
    "        return ssim(img1_y, img2_y)\n",
    "    elif img1.ndim == 3:\n",
    "        if img1.shape[2] == 3:\n",
    "            ssims = []\n",
    "            for i in range(3):\n",
    "                ssims.append(ssim(img1, img2))\n",
    "            return np.array(ssims).mean()\n",
    "        elif img1.shape[2] == 1:\n",
    "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "    else:\n",
    "        raise ValueError('Wrong input image dimensions.')\n",
    "\n",
    "\n",
    "def shuffle_params(m):\n",
    "    if type(m)==nn.Conv2d or type(m)==nn.BatchNorm2d:\n",
    "        param = m.weight\n",
    "        m.weight.data = nn.Parameter(torch.tensor(np.random.normal(0, 1, param.shape)).float())\n",
    "\n",
    "        param = m.bias\n",
    "        m.bias.data = nn.Parameter(torch.zeros(len(param.view(-1))).float().reshape(param.shape))\n",
    "\n",
    "\n",
    "idx = 801\n",
    "\n",
    "num_bits = 1\n",
    "steps = 2000\n",
    "max_iter = 20\n",
    "alpha = 0.1\n",
    "eps = 0.305\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "\n",
    "\n",
    "def img_plot(img):\n",
    "    if img.shape[0] == 1:\n",
    "        plt.imshow(img[0], cmap='gray', vmin=0, vmax=1)\n",
    "    else:\n",
    "        plt.imshow(img.numpy().transpose(1, 2, 0), vmin=0, vmax=1)\n",
    "\n",
    "for seed in [11111, 22222, 33333, 44444, 55555, 66666, 777777, 88888, 99999, 0, 22222, 33333, 44444, 55555, 66666, 777777, 88888, 99999, 0]:\n",
    "    np.random.seed(seed)\n",
    "    model = BasicDecoder(num_bits, hidden_size=128)\n",
    "    model.apply(shuffle_params)\n",
    "    model.to('cuda')\n",
    "\n",
    "    image = samples\n",
    "    save_image(image, 'sample_image.png')\n",
    "\n",
    "    # image = f\"/home/vk352/FaceDetection/datasets/div2k/val/512/{idx:04d}.jpg\"\n",
    "    # image = f\"./xxx_64.jpg\"\n",
    "    # image = imread(image, pilmode='RGB') / 255.0\n",
    "    # image = torch.FloatTensor(image).permute(2, 1, 0).unsqueeze(0)\n",
    "    image = image.to('cuda')\n",
    "    out = model(image)\n",
    "    torch.manual_seed(idx)\n",
    "    target = torch.bernoulli(torch.empty(out.shape).uniform_(0, 1)).to(out.device)\n",
    "    print(target.shape)\n",
    "    eps = eps - 0.005\n",
    "    print(\"eps:\", eps)\n",
    "\n",
    "    adv_image = samples.clone().detach().contiguous()\n",
    "    for i in range(steps // max_iter):\n",
    "        adv_image.requires_grad = True\n",
    "        optimizer = LBFGS([adv_image], lr=alpha, max_iter=max_iter)\n",
    "\n",
    "        def closure():\n",
    "            outputs = model(adv_image)\n",
    "            loss = criterion(outputs, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        delta = torch.clamp(adv_image - image, min=-eps, max=eps)\n",
    "        adv_image = torch.clamp(image + delta, min=0, max=1).detach().contiguous()\n",
    "\n",
    "        acc = len(torch.nonzero((model(adv_image) > 0).float().view(-1) != target.view(-1))) / target.numel()\n",
    "        print(i, acc)\n",
    "        if acc == 0: break\n",
    "\n",
    "    print(seed)\n",
    "    psnr = calc_psnr((image.squeeze().permute(2, 1, 0) * 255).detach().cpu().numpy(),\n",
    "                     (adv_image.squeeze().permute(2, 1, 0) * 255).detach().cpu().numpy())\n",
    "    print(\"psnr:\", psnr)\n",
    "    print(\"ssim:\", calc_ssim((image.squeeze().permute(2, 1, 0) * 255).detach().cpu().numpy(),\n",
    "                             (adv_image.squeeze().permute(2, 1, 0) * 255).detach().cpu().numpy()))\n",
    "    print(\"error:\", acc)\n",
    "    lbfgsimg = (adv_image.cpu().squeeze().permute(2, 1, 0).numpy() * 255).astype(np.uint8)\n",
    "    save_image(adv_image, 'sample_image_stego.png')\n",
    "    if psnr > 19:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x28fb0ca8640>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow((image.squeeze().permute(2,1,0)*255).detach().cpu().numpy().astype(np.uint8))\n",
    "ax[1].imshow((adv_image.squeeze().permute(2,1,0)*255).detach().cpu().numpy().astype(np.uint8))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "gasp",
   "language": "python",
   "display_name": "jupyter_gasp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
